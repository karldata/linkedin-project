{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Linkedln-Project.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"132CrYx11b-bhuXCt0lxMUDNPtgBLONRU","authorship_tag":"ABX9TyP/uz/roxUUIBlD8ZwaTtG9"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87TLOi-zv4kE","executionInfo":{"status":"ok","timestamp":1611535716652,"user_tz":240,"elapsed":653,"user":{"displayName":"Cuong Hv","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggrju2r5tA5YLJ4ibleDbB-d9Nk8g1wLyRTZWU=s64","userId":"15196335600308140853"}},"outputId":"6a9eb4f8-7a35-4d1e-af9b-3f3cbf244b83"},"source":["#To change the working directory\r\n","import os\r\n","os.chdir('/content/drive/My Drive/Colab Notebooks/Applied-Semester-Project')\r\n","!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Applied-Semester-Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bx4XEc8_Wc19","executionInfo":{"status":"ok","timestamp":1611536378772,"user_tz":240,"elapsed":6800,"user":{"displayName":"Cuong Hv","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggrju2r5tA5YLJ4ibleDbB-d9Nk8g1wLyRTZWU=s64","userId":"15196335600308140853"}},"outputId":"edca1b97-441c-4a23-94c0-78da1cd08af2"},"source":["#To install all libraries needed \r\n","!pip install selenium\r\n","!pip install kora -q"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n","\u001b[K     |████████████████████████████████| 61kB 2.5MB/s \n","\u001b[K     |████████████████████████████████| 61kB 5.6MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mH7BNLkQDeXW"},"source":["#Import all libraries needed \r\n","from kora.selenium import wd\r\n","from selenium import webdriver\r\n","from time import sleep\r\n","from bs4 import BeautifulSoup\r\n","import pandas as pd\r\n","from pandas import read_excel\r\n","import csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IkeKRJi3RrXl"},"source":["# Step 1: Login to LinkedIn\r\n","  #This file containt my Linkedin account \r\n","credential = open(\"account.txt\")\r\n","line = credential.readlines()\r\n","username = line[0]\r\n","password = line[1]\r\n","# Open Chrome and login LinkedIn login site\r\n","  # Open Chrome and login \r\n","driver = webdriver.Chrome()\r\n","url = 'https://www.linkedin.com/login'\r\n","driver.get(url)\r\n","sleep(2)\r\n","\r\n","  #Fill in username and password\r\n","email_field = driver.find_element_by_id(\"username\")\r\n","email_field.send_keys(username)\r\n","sleep(2)\r\n","\r\n","password_field = driver.find_element_by_name('session_password')\r\n","password_field.send_keys(password)\r\n","sleep(2)\r\n","\r\n","  #Login \r\n","login_field = driver.find_element_by_xpath('//*[@id=\"app__container\"]/main/div[2]/form/div[3]/button')\r\n","login_field.click()\r\n","sleep(3)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_aSo9cNUBOQ"},"source":["# Step 2: Search for the profile we want to crawl\r\n","    #Locate the search bar\r\n","search_field = driver.find_element_by_xpath('//*[@id=\"ember20\"]/input')\r\n","    #Input the search querry to the search bar\r\n","search_querry = input(\"What profile you want to search?\")\r\n","search_field.send_keys(search_querry)\r\n","    #Search\r\n","search_field.send_keys(Keys.RETURN)\r\n","\r\n","    #Click see all people\r\n","see_all_field = driver.find_element_by_xpath('/html/body/div[7]/div[3]/div/div[2]/div/div[2]/div/div[1]/div/a')\r\n","see_all_field.click()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hLfgD6CbBq8n"},"source":["# Step 3: Scrape the urls of a profile\r\n","def GetURLs_on_Pages():\r\n","    number_of_page = int(input(\"How many pages you want to scrape? \"))\r\n","    URLs_all_page = []\r\n","    for page in range(number_of_page):\r\n","        URLs_one_page = Get_URL()\r\n","        sleep(2)\r\n","        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\r\n","        sleep(2)\r\n","        next_button = driver.find_element_by_class_name('artdeco-pagination__button--next')\r\n","        next_button.click()\r\n","        URLs_all_page += URLs_one_page\r\n","        sleep(2)\r\n","    return URLs_all_page\r\n","\r\n","URLs_all_page = GetURLs_on_Pages()\r\n","URLs_all_page"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkJUzSNk16uK"},"source":["# Step 3: Scrape the urls of the profiles ans save to a CSV\r\n","with open('Linkedin_URLs.txt','w') as f:\r\n","    number_of_page = int(input(\"How many pages you want to scrape? \"))\r\n","    for page in range(number_of_page):\r\n","        URLs_one_page = Get_URL()\r\n","        sleep(2)\r\n","        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\r\n","        sleep(2)\r\n","        next_button = driver.find_element_by_class_name('artdeco-pagination__button--next')\r\n","        next_button.click()\r\n","        f.write(URLs_one_page + '\\n')\r\n","        sleep(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"np6HjN132D_y"},"source":["#Read urls from csv file\r\n","with open('Canada.csv', 'r') as f:\r\n","    URLs_all_page = f.read().split(\"\\n\")\r\n","for linkedin_URL in URLs_all_page:\r\n","    print(linkedin_URL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kw3xEonY2I4m"},"source":["# Step 4: Scrape the info of the profiles ans save to a CSV file\r\n","\r\n","with open('output.csv', 'w', newline = '', encoding='utf8') as f:\r\n","    headers = ['Name', 'Job Title', 'Location', 'Skills', 'URL']\r\n","    writer = csv.DictWriter(f, delimiter=',', lineterminator='\\n', fieldnames=headers)\r\n","    writer.writeheader()\r\n","    for linkedin_URL in URLs_all_page:\r\n","        driver.get(linkedin_URL)\r\n","        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\r\n","        sleep(2)\r\n","        show_more_button = driver.find_element_by_class_name('pv-skills-section__additional-skills')\r\n","        show_more_button.click()\r\n","        page_source = BeautifulSoup(driver.page_source, \"html.parser\")\r\n","        info_div = page_source.find('div', class_ = \"flex-1 mr5\")\r\n","        info_loc = info_div.find_all('ul')\r\n","        name = info_loc[0].find('li').get_text().strip()\r\n","        location = info_loc[1].find('li').get_text().strip()\r\n","        title = info_div.find('h2').get_text().strip()\r\n","        info_skill = page_source.find_all('span', class_ = \"pv-skill-category-entity__name-text t-16 t-black t-bold\")\r\n","        skills = []\r\n","        for skill in info_skill:\r\n","            skills.append(skill.get_text().strip())\r\n","        skills = \", \".join(skills)\r\n","        writer.writerow({headers[0]:name,\r\n","                    headers[1]:title,\r\n","                    headers[2]:location,\r\n","                    headers[3]:skills,\r\n","                    headers[4]:linkedin_URL,\r\n","                    })    \r\n"],"execution_count":null,"outputs":[]}]}